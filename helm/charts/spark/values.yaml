# Default values for spark.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value
global:
  image: minh5/spark
  imageTag: latest
  pullPolicy: IfNotPresent
master:
  name: master
  replicas: 1
  component: "spark-master"
  cpu: "100m"
  memory: "512Mi"
  servicePort: 7077
  containerPort: 7077
  daemonMemory: 1g
webUi:
  name: webui
  servicePort: 8080
  containerPort: 8080
worker:
  name: worker
  replicas: 1
  component: "spark-worker"
  cpu: "100m"
  memory: "512Mi"
  containerPort: 8081
  # Set Worker JVM memory. Default 1g
  daemonMemory: 1g
  # Set how much total memory workers have to give executors
  executorMemory: 1g
driver:
  memory: 4g
executor:
  memory: 4g
notebook:
  url: /pyspark
  service:
    type: ClusterIP
    externalPort: 8888
    internalPort: 8888
persistence:
  enabled: true
  storageClass: generic
  accessMode: ReadWriteOnce
  size: 8Gi