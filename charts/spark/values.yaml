# Default values for spark.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value
global:
  image: minh5/spark
  imageTag: 0.0.2
  pullPolicy: IfNotPresent
Master:
  Name: master
  Replicas: 1
  Component: "spark-master"
  Cpu: "100m"
  Memory: "512Mi"
  ServicePort: 7077
  ContainerPort: 7077
  # Set Master JVM memory. Default 1g
  DaemonMemory: 1g

WebUi:
  Name: webui
  ServicePort: 8080
  ContainerPort: 8080

Worker:
  Name: worker
  Replicas: 1
  Component: "spark-worker"
  Cpu: "100m"
  Memory: "512Mi"
  ContainerPort: 8081
  # Set Worker JVM memory. Default 1g
  DaemonMemory: 1g
  # Set how much total memory workers have to give executors
  ExecutorMemory: 1g
driver:
  memory: 4g
executor:
  memory: 4g
notebook:
  url: /pyspark
  service:
    type: ClusterIP
    externalPort: 8888
    internalPort: 8888
persistence:
  enabled: true
  storageClass: generic
  accessMode: ReadWriteOnce
  size: 8Gi